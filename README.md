# Support-Vector-Classifier-and-KNN
This repository contains a Jupyter Notebook demonstrating two popular supervised machine learning algorithms: Support Vector Machine (SVM) and K-Nearest Neighbors (KNN). Both are widely used for classification tasks and offer different approaches to decision-making.

The notebook covers:

Support Vector Machine (SVM):

Works by finding the optimal hyperplane that maximizes the margin between different classes.

Demonstrates the use of linear, polynomial, and RBF kernels for handling linearly and non-linearly separable data.

Includes visualizations of decision boundaries and margin separation.

K-Nearest Neighbors (KNN):

A simple, instance-based algorithm that classifies samples based on the majority class of their nearest neighbors.

Shows how varying k values affects classification results.

Includes distance metrics (Euclidean, Manhattan) for experimentation.

Both algorithms are implemented using scikit-learn, with NumPy, Pandas, and Matplotlib for data handling and visualization. The notebook applies these models on sample datasets and evaluates performance using metrics such as accuracy, precision, recall, and confusion matrices.

This project is ideal for learners who want to compare margin-based classifiers (SVM) and distance-based classifiers (KNN), gaining a deeper understanding of their strengths, weaknesses, and use cases in real-world problems.
